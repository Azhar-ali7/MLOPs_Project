# ğŸ«€ Heart Disease Prediction - MLOps Pipeline

[![Python 3.11](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/downloads/release/python-3110/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/Docker-ready-blue.svg)](https://www.docker.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A complete MLOps pipeline for heart disease prediction with Docker deployment, full-stack monitoring (ELK + Prometheus/Grafana), and CI/CD automation.

## ğŸ“‘ Table of Contents

- [Overview](#-overview)
- [Architecture](#-architecture)
- [Features](#-features)
- [Quick Start](#-quick-start)
- [Project Structure](#-project-structure)
- [Development Guide](#-development-guide)
- [Deployment](#-deployment)
- [Monitoring](#-monitoring)
- [API Documentation](#-api-documentation)
- [Testing](#-testing)
- [Contributing](#-contributing)

## ğŸ¯ Overview

This project demonstrates a production-ready MLOps pipeline for predicting heart disease using machine learning. It covers the complete ML lifecycle:

1. **Data Acquisition & EDA** - Download and analyze the UCI Heart Disease dataset
2. **Feature Engineering & Modeling** - Train and compare multiple models with hyperparameter tuning
3. **Experiment Tracking** - Track experiments with MLflow
4. **Model Packaging** - Package models for reproducibility
5. **CI/CD Pipeline** - Automated testing with GitHub Actions
6. **Containerization** - Docker for consistent deployment
7. **Production Deployment** - Docker Compose & Kubernetes (Minikube)
8. **Monitoring & Logging** - ELK stack + Prometheus/Grafana

## ğŸ— Architecture

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           MLOps Pipeline                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   Data    â”‚â”€â”€â”€â–¶â”‚   Train   â”‚â”€â”€â”€â–¶â”‚   Model   â”‚â”€â”€â”€â–¶â”‚   API     â”‚          â”‚
â”‚  â”‚  Ingestionâ”‚    â”‚  Pipeline â”‚    â”‚  Registry â”‚    â”‚  Server   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚        â”‚               â”‚                                   â”‚                 â”‚
â”‚        â–¼               â–¼                                   â–¼                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚    EDA    â”‚    â”‚   MLflow  â”‚                      â”‚ Prometheusâ”‚          â”‚
â”‚  â”‚ Notebooks â”‚    â”‚  Tracking â”‚                      â”‚  Metrics  â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                            â”‚                 â”‚
â”‚                                                            â–¼                 â”‚
â”‚                                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚                                                      â”‚  Grafana  â”‚          â”‚
â”‚                                                      â”‚ Dashboard â”‚          â”‚
â”‚                                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚                     ELK Stack (Logging)                        â”‚          â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚          â”‚
â”‚  â”‚  â”‚ Fluentd â”‚â”€â”€â”€â–¶â”‚Elasticsearchâ”‚â”€â”€â”€â–¶â”‚ Kibana  â”‚                  â”‚          â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Docker Compose Services

| Service | Port | Description |
|---------|------|-------------|
| API | 8000 | FastAPI prediction service |
| MLflow | 5000 | Experiment tracking UI |
| Elasticsearch | 9200 | Log storage |
| Kibana | 5601 | Log visualization |
| Fluentd | 24224 | Log collection |
| Prometheus | 9090 | Metrics collection |
| Grafana | 3000 | Metrics dashboards |
| Alertmanager | 9093 | Alert management |

## âœ¨ Features

### Machine Learning
- âœ… Binary classification for heart disease prediction
- âœ… Multiple models (Random Forest, Logistic Regression)
- âœ… Hyperparameter tuning with GridSearchCV
- âœ… Cross-validation for robust evaluation
- âœ… Feature importance analysis

### MLOps
- âœ… Experiment tracking with MLflow
- âœ… Model versioning and registry
- âœ… Reproducible environments
- âœ… CI/CD with GitHub Actions
- âœ… Docker containerization

### Monitoring & Observability
- âœ… Structured JSON logging
- âœ… Centralized logging with ELK stack
- âœ… Prometheus metrics collection
- âœ… Grafana dashboards
- âœ… Alerting with Alertmanager

### API
- âœ… FastAPI with async support
- âœ… OpenAPI documentation
- âœ… Health check endpoints
- âœ… Batch prediction support
- âœ… Request validation

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Docker & Docker Compose
- Git

### Option 1: Docker Compose (Recommended)

```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/MLOPs_Project.git
cd MLOPs_Project

# Start the full stack
./scripts/deploy-local.sh start

# Test the API
./scripts/test-api.sh
```

**Access the services:**
- API: http://localhost:8000
- API Docs: http://localhost:8000/docs
- MLflow: http://localhost:5000
- Kibana: http://localhost:5601
- Prometheus: http://localhost:9090
- Grafana: http://localhost:3000 (admin/admin123)

### Option 2: Local Development

```bash
# Create conda environment
conda env create -f conda-env.yml
conda activate heart-disease-mlops

# Download data
python -m src.download_data

# Train models
python -m src.train

# Run API
uvicorn src.api:app --reload --port 8000
```

## ğŸ“ Project Structure

```
MLOPs_Project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api.py                       # FastAPI application
â”‚   â”œâ”€â”€ api_local.py                 # API with full logging
â”‚   â”œâ”€â”€ data.py                      # Data loading utilities
â”‚   â”œâ”€â”€ model.py                     # Model training/prediction
â”‚   â”œâ”€â”€ train.py                     # Training script
â”‚   â””â”€â”€ download_data.py             # Data download script
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA_Heart_Disease.ipynb   # Exploratory Data Analysis
â”‚   â””â”€â”€ 02_Feature_Engineering_and_Modeling.ipynb
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_api.py                  # API tests
â”‚   â”œâ”€â”€ test_data.py                 # Data module tests
â”‚   â”œâ”€â”€ test_model.py                # Model tests
â”‚   â””â”€â”€ test_integration.py          # Integration tests
â”œâ”€â”€ k8s/
â”‚   â”œâ”€â”€ local/                       # Minikube manifests
â”‚   â”œâ”€â”€ deployment.yaml              # Kubernetes deployment
â”‚   â”œâ”€â”€ service.yaml                 # Kubernetes service
â”‚   â””â”€â”€ README-K8S.md                # K8s deployment guide
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ fluentd/                     # Fluentd configuration
â”‚   â”œâ”€â”€ prometheus/                  # Prometheus configuration
â”‚   â”œâ”€â”€ grafana/                     # Grafana dashboards
â”‚   â””â”€â”€ alertmanager/                # Alertmanager configuration
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ deploy-local.sh              # Local deployment script
â”‚   â”œâ”€â”€ deploy-k8s-local.sh          # Minikube deployment
â”‚   â””â”€â”€ test-api.sh                  # API testing script
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                         # Raw data
â”‚   â””â”€â”€ processed/                   # Processed data
â”œâ”€â”€ models/                          # Saved models
â”œâ”€â”€ docs/                            # Documentation
â”œâ”€â”€ docker-compose.local.yml         # Full stack deployment
â”œâ”€â”€ Dockerfile.local                 # Docker image for local
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ requirements-local.txt           # Local deployment deps
â””â”€â”€ README.md                        # This file
```

## ğŸ’» Development Guide

### Setting Up Development Environment

```bash
# Using conda
conda env create -f conda-env.yml
conda activate heart-disease-mlops

# Or using pip
pip install -r requirements.txt
```

### Running the Notebooks

```bash
# Start Jupyter
jupyter notebook notebooks/
```

### Training Models

```bash
# Train with MLflow tracking
python -m src.train

# View experiments
mlflow ui --port 5000
```

### Running Tests

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=src --cov-report=html
```

## ğŸš¢ Deployment

### Docker Compose Deployment

```bash
# Start all services
./scripts/deploy-local.sh start

# View logs
./scripts/deploy-local.sh logs

# Stop services
./scripts/deploy-local.sh stop

# Clean up
./scripts/deploy-local.sh clean
```

### Kubernetes Deployment (Minikube)

```bash
# Deploy to Minikube
./scripts/deploy-k8s-local.sh deploy

# Check status
./scripts/deploy-k8s-local.sh status

# Get service URL
minikube service heart-disease-api-service -n heart-disease --url

# Delete deployment
./scripts/deploy-k8s-local.sh delete
```

See [k8s/README-K8S.md](k8s/README-K8S.md) for detailed Kubernetes instructions.

## ğŸ“Š Monitoring

### Logging (ELK Stack)

Access Kibana at http://localhost:5601 to:
- Search and filter logs
- Create log visualizations
- Set up log-based alerts

### Metrics (Prometheus + Grafana)

**Prometheus** (http://localhost:9090):
- Query metrics
- View targets and alerts
- Explore metric labels

**Grafana** (http://localhost:3000):
- Pre-configured API dashboard
- Request latency graphs
- Prediction distribution charts
- Login: admin/admin123

### Available Metrics

| Metric | Type | Description |
|--------|------|-------------|
| `api_requests_total` | Counter | Total requests by endpoint |
| `api_request_latency_seconds` | Histogram | Request latency distribution |
| `api_predictions_total` | Counter | Predictions by result |
| `api_prediction_probability` | Histogram | Prediction probabilities |

## ğŸ“š API Documentation

### Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Welcome message |
| `/health` | GET | Health check |
| `/predict` | POST | Single prediction |
| `/predict/batch` | POST | Batch predictions |
| `/metrics` | GET | Prometheus metrics |
| `/docs` | GET | Swagger UI |

### Example Request

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "data": [{
      "age": 55,
      "sex": 1,
      "cp": 2,
      "trestbps": 130,
      "chol": 250,
      "fbs": 0,
      "restecg": 0,
      "thalach": 150,
      "exang": 0,
      "oldpeak": 1.0,
      "slope": 1,
      "ca": 0,
      "thal": 2
    }]
  }'
```

### Response Format

```json
{
  "predictions": [1],
  "probabilities": [[0.25, 0.75]],
  "model": "random_forest"
}
```

## ğŸ§ª Testing

### Unit Tests

```bash
pytest tests/test_data.py -v
pytest tests/test_model.py -v
```

### Integration Tests

```bash
pytest tests/test_api.py -v
pytest tests/test_integration.py -v
```

### API Tests

```bash
# Using test script
./scripts/test-api.sh

# Using curl
curl http://localhost:8000/health
```

## ğŸ“– Documentation

- [Local Deployment Guide](docs/LOCAL_DEPLOYMENT.md)
- [Kubernetes Deployment](k8s/README-K8S.md)
- [Video Demonstration Guide](docs/VIDEO_GUIDE.md)
- [Final Report Template](docs/FINAL_REPORT_TEMPLATE.md)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- UCI Machine Learning Repository for the Heart Disease dataset
- FastAPI for the excellent web framework
- MLflow for experiment tracking
- The open-source community for amazing tools

---

**Made with â¤ï¸ for MLOps learning**
