<system>
  log_level info
</system>

# Receive JSON logs from API log file
<source>
  @type tail
  path /app/logs/api.log
  pos_file /tmp/api.log.pos
  tag api.logs
  read_from_head true
  <parse>
    @type json
    time_key timestamp
    time_type string
    time_format %Y-%m-%dT%H:%M:%S.%NZ
  </parse>
</source>

# Receive logs via forward protocol from Docker
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

# Add additional fields
<filter api.**>
  @type record_transformer
  <record>
    hostname "#{Socket.gethostname}"
    environment local
    cluster local-docker
  </record>
</filter>

# Route prediction events to separate index
<filter api.**>
  @type record_transformer
  enable_ruby true
  <record>
    index_name ${record["event"] == "prediction_complete" ? "predictions" : "api-logs"}
  </record>
</filter>

# Output to Elasticsearch
<match api.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix mlops-api
  logstash_dateformat %Y.%m.%d
  include_tag_key true
  type_name _doc
  tag_key @log_name
  flush_interval 5s
  
  <buffer>
    @type memory
    flush_mode interval
    flush_interval 5s
    chunk_limit_size 5MB
    retry_max_times 3
    retry_wait 10s
  </buffer>
</match>

# Catch all other logs
<match **>
  @type elasticsearch
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix docker-logs
  logstash_dateformat %Y.%m.%d
  include_tag_key true
  type_name _doc
  tag_key @log_name
  flush_interval 10s
  
  <buffer>
    @type memory
    flush_mode interval
    flush_interval 10s
    chunk_limit_size 5MB
    retry_max_times 3
  </buffer>
</match>
